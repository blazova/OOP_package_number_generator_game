{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    \n",
    "    \"\"\" Representing a game of guessing a computer generated number within a set range. \n",
    "             \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, players, max_number):\n",
    "        self.max_number = max_number\n",
    "        self.players = players        \n",
    "                  \n",
    "    def play_game(self):\n",
    "        \n",
    "        \"\"\" Starts a game of guessing a computer generated number within a set range. \n",
    "        \n",
    "        Attributes:\n",
    "        players (list) representing the Computer player and the Player \n",
    "            who interacts with the program\n",
    "        max_number (int) representing the max limmit of the range of integerswithin \n",
    "            which the computer chooses a randomn integer  \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        attempts = 1\n",
    "        picked_number = self.players[0].pick_number(self.max_number)   \n",
    "        guess = self.players[1].guess_number(self.max_number, response=None)\n",
    "        \n",
    "#         print(guess)\n",
    "        \n",
    "        while guess != picked_number:\n",
    "            print(guess)\n",
    "            \n",
    "            if guess > picked_number:\n",
    "                response = 'lower' \n",
    "                print(\"Too high. The generated number is lower.\")\n",
    "#                 output = int(input(\"Try again. The number is between 0 and {}.\".format(max_number)))\n",
    "                \n",
    "        \n",
    "            if guess < picked_number:\n",
    "                response = 'higher'\n",
    "                print(\"Too low. The number is greater than {}.\".format(guess))\n",
    "#                 output = int(input(\"Try again. The number is between 0 and {}.\".format(max_number)))    \n",
    "\n",
    "            attempts += 1\n",
    "            guess = self.players[1].guess_number(self.max_number, response=response)\n",
    "        \n",
    "        print(guess)\n",
    "        print(\"Dobre! You made it on {} attempt(s).\".format(attempts))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def pick_number(self, max_number):\n",
    "        \"\"\"\n",
    "        Returns an int\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def guess_number(self, max_number, response=None):\n",
    "        \"\"\"\n",
    "        Returns an int\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputerPlayer(Player):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name = 'computersko')\n",
    "        self.previous_guess = None\n",
    "        \n",
    "    def pick_number(self, max_number):\n",
    "        return randint(0, max_number)\n",
    "    \n",
    "    def guess_number(self,max_number, response = None):\n",
    "        sleep(1)\n",
    "        if response is None:\n",
    "            self.previous_guess = randint(0, max_number)\n",
    "        elif response == 'lower':\n",
    "            self.previous_guess = randint(0, self.previous_guess)\n",
    "        elif response == 'higher':\n",
    "            self.previous_guess = randint(self.previous_guess, max_number)\n",
    "\n",
    "        return self.previous_guess\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "computersko = ComputerPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonPlayer(Player):\n",
    "    \n",
    "    def pick_number(self, max_number):\n",
    "        return int(input(\"Pick a number within 0 and {} and let the Computer guess.\".format(max_number)))\n",
    "    \n",
    "    def guess_number(self, max_number, response=None):\n",
    "        return int(input(\"Guess a number within the range of 0 and {}\".format(max_number)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = PersonPlayer('katzko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamesko = Game(players = [person, computersko], max_number=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pick a number within 0 and 20. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Too high. The generated number is lower.\n",
      "5\n",
      "Too high. The generated number is lower.\n",
      "2\n",
      "Too high. The generated number is lower.\n",
      "0\n",
      "Too low. The number is greater than 0.\n",
      "19\n",
      "Too high. The generated number is lower.\n",
      "13\n",
      "Too high. The generated number is lower.\n",
      "10\n",
      "Too high. The generated number is lower.\n",
      "5\n",
      "Too high. The generated number is lower.\n",
      "2\n",
      "Too high. The generated number is lower.\n",
      "2\n",
      "Too high. The generated number is lower.\n",
      "1\n",
      "Dobre! You made it on 11 attempt(s).\n"
     ]
    }
   ],
   "source": [
    "gamesko.play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in ./env2/lib/python3.6/site-packages (2.9.1)\n",
      "Requirement already satisfied: py>=1.4.29 in ./env2/lib/python3.6/site-packages (from pytest) (1.8.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: py.test [options] [file_or_dir] [file_or_dir] [...]\n",
      "\n",
      "positional arguments:\n",
      "  file_or_dir\n",
      "\n",
      "general:\n",
      "  -k EXPRESSION         only run tests which match the given substring\n",
      "                        expression. An expression is a python evaluatable\n",
      "                        expression where all names are substring-matched\n",
      "                        against test names and their parent classes. Example:\n",
      "                        -k 'test_method or test other' matches all test\n",
      "                        functions and classes whose name contains\n",
      "                        'test_method' or 'test_other'. Additionally keywords\n",
      "                        are matched to classes and functions containing extra\n",
      "                        names in their 'extra_keyword_matches' set, as well as\n",
      "                        functions which have names assigned directly to them.\n",
      "  -m MARKEXPR           only run tests matching given mark expression.\n",
      "                        example: -m 'mark1 and not mark2'.\n",
      "  --markers             show markers (builtin, plugin and per-project ones).\n",
      "  -x, --exitfirst       exit instantly on first error or failed test.\n",
      "  --maxfail=num         exit after first num failures or errors.\n",
      "  --strict              run pytest in strict mode, warnings become errors.\n",
      "  -c file               load configuration from `file` instead of trying to\n",
      "                        locate one of the implicit configuration files.\n",
      "  --fixtures, --funcargs\n",
      "                        show available fixtures, sorted by plugin appearance\n",
      "  --import-mode={prepend,append}\n",
      "                        prepend/append to sys.path when importing test\n",
      "                        modules, default is to prepend.\n",
      "  --pdb                 start the interactive Python debugger on errors.\n",
      "  --capture=method      per-test capturing method: one of fd|sys|no.\n",
      "  -s                    shortcut for --capture=no.\n",
      "  --runxfail            run tests even if they are marked xfail\n",
      "  --lf, --last-failed   rerun only the tests that failed at the last run (or\n",
      "                        all if none failed)\n",
      "  --ff, --failed-first  run all tests but run the last failures first. This\n",
      "                        may re-order tests and thus lead to repeated fixture\n",
      "                        setup/teardown\n",
      "  --cache-show          show cache contents, don't perform collection or tests\n",
      "  --cache-clear         remove all cache contents at start of test run.\n",
      "  --pylint              run pylint on all\n",
      "  --no-pylint           disable running pylint\n",
      "  --pylint-rcfile=PYLINT_RCFILE\n",
      "                        Location of RC file if not pylintrc\n",
      "  --pylint-error-types=PYLINT_ERROR_TYPES\n",
      "                        The types of pylint errors to consider failures by\n",
      "                        letter, default is all of them (CRWEF).\n",
      "  --pylint-jobs=PYLINT_JOBS\n",
      "                        Specify number of processes to use for pylint\n",
      "\n",
      "reporting:\n",
      "  -v, --verbose         increase verbosity.\n",
      "  -q, --quiet           decrease verbosity.\n",
      "  -r chars              show extra test summary info as specified by chars\n",
      "                        (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed\n",
      "                        (w)pytest-warnings (p)passed, (P)passed with output,\n",
      "                        (a)all except pP.\n",
      "  -l, --showlocals      show locals in tracebacks (disabled by default).\n",
      "  --report=opts         (deprecated, use -r)\n",
      "  --tb=style            traceback print mode (auto/long/short/line/native/no).\n",
      "  --full-trace          don't cut any tracebacks (default is to cut).\n",
      "  --color=color         color terminal output (yes/no/auto).\n",
      "  --durations=N         show N slowest setup/test durations (N=0 for all).\n",
      "  --pastebin=mode       send failed|all info to bpaste.net pastebin service.\n",
      "  --junit-xml=path      create junit-xml style report file at given path.\n",
      "  --junit-prefix=str    prepend prefix to classnames in junit-xml output\n",
      "  --result-log=path     path for machine-readable result log.\n",
      "\n",
      "collection:\n",
      "  --collect-only        only collect tests, don't execute them.\n",
      "  --pyargs              try to interpret all arguments as python packages.\n",
      "  --ignore=path         ignore path during collection (multi-allowed).\n",
      "  --confcutdir=dir      only load conftest.py's relative to specified dir.\n",
      "  --noconftest          Don't load any conftest.py files.\n",
      "  --doctest-modules     run doctests in all .py modules\n",
      "  --doctest-glob=pat    doctests file matching pattern, default: test*.txt\n",
      "  --doctest-ignore-import-errors\n",
      "                        ignore doctest ImportErrors\n",
      "\n",
      "test session debugging and configuration:\n",
      "  --basetemp=dir        base temporary directory for this test run.\n",
      "  --version             display pytest lib version and import information.\n",
      "  -h, --help            show help message and configuration info\n",
      "  -p name               early-load given plugin (multi-allowed). To avoid\n",
      "                        loading of plugins, use the `no:` prefix, e.g.\n",
      "                        `no:doctest`.\n",
      "  --trace-config        trace considerations of conftest.py files.\n",
      "  --debug               store internal tracing debug information in\n",
      "                        'pytestdebug.log'.\n",
      "  --assert=MODE         control assertion debugging tools. 'plain' performs no\n",
      "                        assertion debugging. 'reinterp' reinterprets assert\n",
      "                        statements after they failed to provide assertion\n",
      "                        expression information. 'rewrite' (the default)\n",
      "                        rewrites assert statements in test modules on import\n",
      "                        to provide assert expression information.\n",
      "  --no-assert           DEPRECATED equivalent to --assert=plain\n",
      "  --no-magic            DEPRECATED equivalent to --assert=plain\n",
      "  --genscript=path      create standalone pytest script at given target path.\n",
      "\n",
      "\n",
      "[pytest] ini-options in the next pytest.ini|tox.ini|setup.cfg file:\n",
      "\n",
      "  markers (linelist)       markers for test functions\n",
      "  norecursedirs (args)     directory patterns to avoid for recursion\n",
      "  testpaths (args)         directories to search for tests when no files or dire\n",
      "  usefixtures (args)       list of default fixtures to be used with this project\n",
      "  python_files (args)      glob-style file patterns for Python test module disco\n",
      "  python_classes (args)    prefixes or glob names for Python test class discover\n",
      "  python_functions (args)  prefixes or glob names for Python test function and m\n",
      "  xfail_strict (bool)      default for the strict parameter of xfail markers whe\n",
      "  doctest_optionflags (args) option flags for doctests\n",
      "  addopts (args)           extra command line options\n",
      "  minversion (string)      minimally required pytest version\n",
      "\n",
      "environment variables:\n",
      "  PYTEST_ADDOPTS           extra command line options\n",
      "  PYTEST_PLUGINS           comma-separated plugins to load during startup\n",
      "  PYTEST_DEBUG             set to enable debug tracing of pytest's internals\n",
      "\n",
      "\n",
      "to see available markers type: py.test --markers\n",
      "to see available fixtures type: py.test --fixtures\n",
      "(shown according to specified file_or_dir or current dir if not specified)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# def play_game(max_number, generated_number):\n",
    "#     attempts = 1\n",
    "\n",
    "#     players_guess = input(\"Computer chose a random integer between 0 and {}. Can you guess the number?\".format(max_nunmber))\n",
    "#     output = int(players_guess)\n",
    "#     while output != generated_number:\n",
    "\n",
    "#         if output > generated_number:\n",
    "#             attempts += 1\n",
    "#             print(\"Too high. The generated number is lower.\")\n",
    "#             output = int(input(\"Computer chose a random integer between 0 and {}. Can you guess the number?\".format(max_number)))\n",
    "\n",
    "#         if output < generated_number:\n",
    "#             attempts += 1\n",
    "#             print(\"Too low. The number is greater than {}.\".format(players_guess))\n",
    "#             output = int(input(\"Computer chose a random integer between 0 and {}. Can you guess the number?\".format(max_number)))    \n",
    "                \n",
    "#     print(\"Dobre! You made it on {} attempt(s).\".format(attempts))\n",
    "\n",
    "        \n",
    "# play_game(20,17)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# def random_number(max_number):\n",
    "#     print(randint(0, max_number))\n",
    "        \n",
    "# random_number(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# def random_number(max_number):\n",
    "#     return input(\"Computer chose a random integer between 0 and {}. Can you guess the number?\".format(max_number))\n",
    "    \n",
    "# #     print(randint(0, max_number))\n",
    "\n",
    "# random_number(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing data types\n",
    "\n",
    "# players_guess = input(\"Computer chose a random integer between 0 and {}. Can you guess the number?\".format(17))\n",
    "# players_guess\n",
    "# type(players_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_guess = int(players_guess)\n",
    "# type(players_guess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
